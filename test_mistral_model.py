#!/usr/bin/env python3
"""
Test Mistral model functionality directly
"""

import os

def test_mistral_model():
    """Test Mistral model loading and basic generation"""
    try:
        from llama_cpp import Llama
        
        model_path = 'models/mistral-7b-instruct-v0.2.Q4_K_M.gguf'
        
        if not os.path.exists(model_path):
            print(f"âŒ Model file not found: {model_path}")
            return False
        
        print(f"âœ… Model file exists: {model_path}")
        print("ğŸ§  Testing Mistral model initialization...")
        
        # Initialize with minimal settings
        llm = Llama(
            model_path=model_path,
            n_ctx=1024,
            n_threads=4,
            verbose=False
        )
        
        print("âœ… Mistral model loaded successfully!")
        
        # Test simple generation
        test_prompt = "Hello, this is a test. Please respond in Japanese:"
        response = llm(test_prompt, max_tokens=50, temperature=0.3, stream=False)
        generated_text = str(response['choices'][0]['text']).strip()
        
        print(f"Test response: {generated_text}")
        
        # Test Japanese academic summarization
        academic_prompt = """
ã‚ãªãŸã¯å­¦è¡“è«–æ–‡ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç ”ç©¶è«–æ–‡ã‚’æ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š

ç ”ç©¶å†…å®¹:
This paper presents a novel FPGA-based implementation for digital signal processing applications.

æ—¥æœ¬èªè¦ç´„ï¼š"""
        
        response = llm(academic_prompt, max_tokens=200, temperature=0.3, stream=False)
        academic_summary = str(response['choices'][0]['text']).strip()
        
        print(f"Academic test summary: {academic_summary}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ ImportError: {e}")
        print("ğŸ“¦ Please install llama-cpp-python")
        return False
    except Exception as e:
        print(f"âŒ Error testing Mistral model: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_mistral_model()
    print(f"\nMistral test result: {'SUCCESS' if success else 'FAILED'}")
