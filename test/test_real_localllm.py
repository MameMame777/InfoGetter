#!/usr/bin/env python3
"""
Real LocalLLM Test Script
=========================

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€True LocalLLMã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãªã—ã®ç´”ç²‹ãªLocalLLMçµ±åˆã§ã™ã€‚
"""

import sys
import os
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.utils.real_localllm_summarizer import RealLocalLLMSummarizer

def test_real_localllm():
    """Real LocalLLMã®ãƒ†ã‚¹ãƒˆ"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    logger = logging.getLogger("RealLocalLLMTest")
    logger.info("ğŸš€ Starting Real LocalLLM Test")
    
    try:
        # Real LocalLLMåˆæœŸåŒ–
        logger.info("Initializing Real LocalLLM Summarizer...")
        summarizer = RealLocalLLMSummarizer()
        
        # åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
        logger.info(f"Real LocalLLM Available: {summarizer.is_available()}")
        
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        test_files = [
            "arxiv_recent_papers.json",
            "results/fpga_documents.json"
        ]
        
        for test_file in test_files:
            if os.path.exists(test_file):
                logger.info(f"ğŸ“„ Testing with file: {test_file}")
                
                # Real LocalLLMå‡¦ç†ã®å®Ÿè¡Œ
                result = summarizer.summarize_results(test_file)
                
                # çµæœè¡¨ç¤º
                logger.info("âœ… Real LocalLLM processing completed successfully!")
                logger.info(f"Processing Method: {result.get('processing_method', 'Unknown')}")
                logger.info(f"Model Info: {result.get('model_info', {})}")
                logger.info(f"Summary Length: {len(result.get('summary', ''))}")
                logger.info(f"LLM Error Detected: {result.get('llm_error_detected', True)}")
                
                # è¦ç´„ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
                summary = result.get('summary', '')
                if summary:
                    logger.info(f"Summary Preview (first 200 chars): {summary[:200]}...")
                
                break
        else:
            logger.warning("No test files found. Creating a test file...")
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            test_data = [
                {
                    "title": "Test FPGA Document",
                    "abstract": "This is a test abstract about FPGA technology for Real LocalLLM testing.",
                    "content": "Test content about Field Programmable Gate Arrays and their applications."
                }
            ]
            
            import json
            test_file = "test_localllm_data.json"
            with open(test_file, 'w', encoding='utf-8') as f:
                json.dump(test_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Created test file: {test_file}")
            
            # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§å‡¦ç†
            result = summarizer.summarize_results(test_file)
            logger.info("âœ… Real LocalLLM test processing completed!")
            logger.info(f"Result: {result}")
            
    except Exception as e:
        logger.error(f"âŒ Real LocalLLM Test Failed: {e}")
        logger.error("This error indicates that Real LocalLLM is not properly configured.")
        logger.error("Please ensure:")
        logger.error("1. LocalLLM library is properly installed")
        logger.error("2. llama-cpp-python is installed")
        logger.error("3. A GGUF model file is available in models/ directory")
        raise

if __name__ == "__main__":
    test_real_localllm()
