#!/usr/bin/env python3
"""
Seleniumå°‚ç”¨Xilinxã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import yaml
import json
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from src.scrapers.xilinx_scraper import XilinxScraper
from utils.log_manager import clear_log_file


def test_selenium_only_xilinx():
    """Seleniumå°‚ç”¨Xilinxã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("Seleniumå°‚ç”¨Xilinxã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–
    print("ğŸ—‚ï¸ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    clear_log_file()
    
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        config_path = os.path.join(project_root, 'config', 'settings.yaml')
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        xilinx_config = config['data_sources']['xilinx']
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’åˆæœŸåŒ–
        scraper = XilinxScraper(xilinx_config)
        
        # URLæ§‹ç¯‰ã‚’ãƒ†ã‚¹ãƒˆ
        search_url = scraper._build_search_url()
        print(f"ğŸ”— æ§‹ç¯‰ã•ã‚ŒãŸURL: {search_url}")
        
        # è¨­å®šå€¤ã‚’ç¢ºèª
        print(f"ğŸ“Š è¨­å®šå€¤:")
        print(f"  strategy: {xilinx_config.get('strategy', 'unknown')}")
        print(f"  max_results: {xilinx_config.get('max_results', 100)}")
        print(f"  scroll_pages: {xilinx_config.get('scroll_pages', 5)}")
        print(f"  query: {xilinx_config.get('search_params', {}).get('query', 'Unknown')}")
        
        # URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
        if 'query=DSP' in search_url:
            print("  âœ… DSPã‚¯ã‚¨ãƒªãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
        else:
            print("  âŒ DSPã‚¯ã‚¨ãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
        if 'value-filters=' in search_url:
            print("  âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
        else:
            print("  âŒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        print("\nğŸš€ Seleniumã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...")
        print("â³ ãƒ–ãƒ©ã‚¦ã‚¶ã®èµ·å‹•ã¨ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã‚’å¾…æ©Ÿä¸­...")
        
        documents = scraper.scrape_documents()
        
        print(f"âœ… å–å¾—å®Œäº†: {len(documents)} ä»¶")
        
        if documents:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            urls = [doc.url for doc in documents]
            unique_urls = set(urls)
            duplicate_count = len(urls) - len(unique_urls)
            
            print(f"ğŸ“ˆ é‡è¤‡åˆ†æ:")
            print(f"  ç·ä»¶æ•°: {len(urls)}")
            print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯: {len(unique_urls)}")
            print(f"  é‡è¤‡: {duplicate_count}")
            
            if duplicate_count > 0:
                print(f"  é‡è¤‡ç‡: {duplicate_count / len(urls) * 100:.1f}%")
            else:
                print("  é‡è¤‡ç‡: 0% (å®Œç’§ï¼)")
            
            # æœŸå¾…ã•ã‚Œã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ç¢ºèª
            expected_docs = [
                'system generator',
                'fir compiler',
                'fft',
                'dsp',
                'versal',
                'zynq',
                'vivado',
                'user guide',
                'manual',
                'ip core'
            ]
            
            found_expected = {}
            for expected in expected_docs:
                count = sum(1 for doc in documents if expected.lower() in doc.name.lower())
                found_expected[expected] = count
            
            print(f"\nğŸ“‹ æœŸå¾…ã•ã‚Œã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—:")
            total_expected = 0
            for doc_type, count in found_expected.items():
                status = "âœ…" if count > 0 else "âŒ"
                total_expected += count
                print(f"  {status} {doc_type}: {count} ä»¶")
            
            print(f"\nğŸ¯ æœŸå¾…ã•ã‚Œã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç·æ•°: {total_expected} ä»¶")
            
            # å…·ä½“çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
            specific_docs = {
                'System Generator': [doc for doc in documents if 'system generator' in doc.name.lower()],
                'FIR Compileré–¢é€£': [doc for doc in documents if 'fir compiler' in doc.name.lower() or 'fir' in doc.name.lower()],
                'FFTé–¢é€£': [doc for doc in documents if 'fft' in doc.name.lower()],
                'DSPé–¢é€£': [doc for doc in documents if 'dsp' in doc.name.lower()],
                'Versalé–¢é€£': [doc for doc in documents if 'versal' in doc.name.lower()],
                'Zynqé–¢é€£': [doc for doc in documents if 'zynq' in doc.name.lower()]
            }
            
            for category, docs in specific_docs.items():
                if docs:
                    print(f"\nğŸ¯ {category}: {len(docs)} ä»¶")
                    for i, doc in enumerate(docs[:3]):  # æœ€åˆã®3ä»¶ã®ã¿è¡¨ç¤º
                        print(f"  {i+1}. {doc.name}")
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
            categories = {}
            fpga_series = {}
            
            for doc in documents:
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
                cat = doc.category or 'Unknown'
                categories[cat] = categories.get(cat, 0) + 1
                
                # FPGAã‚·ãƒªãƒ¼ã‚ºåˆ¥é›†è¨ˆ
                series = doc.fpga_series or 'Unknown'
                fpga_series[series] = fpga_series.get(series, 0) + 1
            
            print(f"\nğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ:")
            for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
                print(f"  {category}: {count}")
            
            print(f"\nğŸ”§ FPGAã‚·ãƒªãƒ¼ã‚ºåˆ¥é›†è¨ˆ:")
            for series, count in sorted(fpga_series.items(), key=lambda x: x[1], reverse=True):
                print(f"  {series}: {count}")
            
            # æ¤œç´¢URLã®ç¢ºèª
            search_url_from_doc = documents[0].search_url
            print(f"\nğŸ”— å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸæ¤œç´¢URL:")
            print(f"  {search_url_from_doc}")
            
            # å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
            print(f"\nğŸ“ å…¨å–å¾—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
            for i, doc in enumerate(documents):
                print(f"  {i+1:2d}. {doc.name}")
                print(f"      URL: {doc.url}")
                print(f"      ã‚«ãƒ†ã‚´ãƒª: {doc.category}")
                print(f"      FPGAã‚·ãƒªãƒ¼ã‚º: {doc.fpga_series}")
                print()
            
            # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            results_file = os.path.join(project_root, 'results', 'selenium_xilinx_test_results.json')
            os.makedirs(os.path.dirname(results_file), exist_ok=True)
            
            # çµæœã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
            serializable_results = {
                'timestamp': datetime.now().isoformat(),
                'search_url': search_url,
                'total_documents': len(documents),
                'unique_documents': len(unique_urls),
                'duplicate_count': duplicate_count,
                'expected_documents_found': total_expected,
                'categories': categories,
                'fpga_series': fpga_series,
                'specific_documents': {k: len(v) for k, v in specific_docs.items()},
                'documents': [
                    {
                        'name': doc.name,
                        'url': str(doc.url),
                        'category': doc.category,
                        'fpga_series': doc.fpga_series,
                        'file_type': doc.file_type,
                        'search_url': str(doc.search_url) if doc.search_url else None
                    }
                    for doc in documents
                ]
            }
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ’¾ çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {results_file}")
        else:
            print("âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            print("   ãƒšãƒ¼ã‚¸ã®æ§‹é€ ãŒå¤‰ã‚ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_selenium_only_xilinx()
    
    if success:
        print("\nğŸ‰ Seleniumå°‚ç”¨Xilinxã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
    else:
        print("\nğŸ’¥ ãƒ†ã‚¹ãƒˆå¤±æ•—")
        sys.exit(1)